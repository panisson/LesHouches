{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "display_name": "IPython (Python 2)",
   "language": "python",
   "name": "python2"
  },
  "name": "",
  "signature": "sha256:846acc4161eb7b8fd1079574b30eae48a044fe72f07fd88e4ec3917af38896a3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Complex Networks Thematic School, Les Houches, April 7-18, 2014\n",
      "\n",
      "---\n",
      "\n",
      "# Introduction to Python Tools - Network Analysis (2)\n",
      "\n",
      "##Dr. Andr\u00e9 Panisson\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataset used in this demo was extracted from the Stack Exchange network.\n",
      "\n",
      "The last updated dataset can be found here:\n",
      "https://archive.org/details/stackexchange.\n",
      "\n",
      "It is a small sample of the full dataset, with 10000 questions with Id, Title, Body and associated Tags.\n",
      "\n",
      "In this demo, we will create a matrix of tag co-ccurrence, and transform this matrix in a network of tags."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we load the data using `read_csv`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"data/stackoverflow.csv.gz\", compression='gzip')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can make a selection (projection) of the table columns using the fancy indexing syntax:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tags = df[['Tags']]\n",
      "tags.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we create a counter to count how many times each tag appears in the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "tags_counter = Counter()\n",
      "for stags in tags.Tags:\n",
      "    tags_counter.update(stags.split())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and show the 10 most common tags:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tags_counter.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our dataset is composed of around 5000 tags. However, we would like to analyse just the most common tags. Let's select the 1500 most common tags and create a dictionary where each tag is associated to an integer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocabulary = dict((t, i) for i, (t, c) in enumerate(tags_counter.most_common(1500)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the most common formats used to analyse text is the term count matrix.\n",
      "\n",
      "This matrix is composed of N rows and M columns, where N is the number of documents (10000 questions in our case) and M is the number of terms in the vocabulary (1500 in our case).\n",
      "\n",
      "Each row of this matrix is known as a term vector. We will create a term vector for each question.\n",
      "\n",
      "Since it is a very sparse matrix, we will use a sparse matrix implementation (coo_matrix, a sparse matrix in coordinate format) from Scipy to represent it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import sparse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function that creates a term vector\n",
      "def term_vector(tagrow):\n",
      "    cols = [vocabulary[t] for t in tagrow.split() if t in vocabulary]\n",
      "    rows = zeros(len(cols))\n",
      "    values = ones(len(cols))\n",
      "    return sparse.coo_matrix((values, (rows, cols)), shape=(1, len(vocabulary)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = sparse.vstack(term_vector(tagrow) for tagrow in tags.Tags)\n",
      "M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's create a matrix of tag co-ccurrence. Each position of this matrix contains the number of times the tag i appears with tag j in the same document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tag co-occurrence\n",
      "tag_coocurrence = M.T.dot(M)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tag_coocurrence.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we use networkx to export the network of tags to a graphml file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "\n",
      "g = nx.Graph()\n",
      "\n",
      "vocabulary_inv = dict((v,k) for k,v in vocabulary.iteritems())\n",
      "\n",
      "for i in range(len(vocabulary_inv)):\n",
      "    g.add_node(i, name=vocabulary_inv[i], Label=vocabulary_inv[i])\n",
      "\n",
      "for i,j in zip(*tag_coocurrence.nonzero()):\n",
      "    g.add_edge(i, j, Weight=float(tag_coocurrence[i,j]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_graphml(g, \"data/tags.graphml\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}